{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ensembles\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hard votiong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**soft voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#'bootstrap=True' means that bagging is used\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, random_state=42, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**oob score** \n",
    "\n",
    "(похоже на использование validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9253333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, random_state=42, oob_score=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92.5% - неплохо. Проверим на тестовом наборе по фану"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score by training set: 95.2%\n",
      "accuracy score by test set: 91.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd_clf.predict(X_train)\n",
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"accuracy score by training set: {:.4}%\".format(acc*100))\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score by test set: {:.4}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь почти тоже самое, но используя **BagginClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score by training set: 93.87%\n",
      "accuracy score by test set: 92.0%\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter='random', random_state=42, max_leaf_nodes=16),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, random_state=42, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bag_clf.predict(X_train)\n",
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"accuracy score by training set: {:.4}%\".format(acc*100))\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score by test set: {:.4}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже, но с использованием **ExtraTreesClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score by training set: 92.53%\n",
      "accuracy score by test set: 91.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extra_clf = ExtraTreesClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "extra_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = extra_clf.predict(X_train)\n",
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"accuracy score by training set: {:.4}%\".format(acc*100))\n",
    "\n",
    "y_pred = extra_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score by test set: {:.4}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature impotance / Iris dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11249225099876375\n",
      "sepal width (cm) 0.02311928828251033\n",
      "petal length (cm) 0.4410304643639577\n",
      "petal width (cm) 0.4233579963547682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature impotance / MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.target = mnist.target.astype(np.uint8)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(mnist[\"data\"], mnist[\"target\"], \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on training set: 100.0%\n",
      "accuracy score on test set: 96.73%\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rnd_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rnd_clf.predict(x_train)\n",
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"accuracy score on training set: {:.4}%\".format(acc*100))\n",
    "\n",
    "y_pred = rnd_clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score on test set: {:.4}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = rnd_clf.feature_importances_.reshape(28, 28)\n",
    "plt.imshow(image, cmap = mpl.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
